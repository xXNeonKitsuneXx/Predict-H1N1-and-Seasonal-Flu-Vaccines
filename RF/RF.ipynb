{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\xxneo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_features = pd.read_csv(\"./training_set_features.csv\")\n",
    "train_labels = pd.read_csv(\"./training_set_labels.csv\")\n",
    "test_features = pd.read_csv(\"./test_set_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for H1N1 Vaccine: 0.8294\n",
      "ROC AUC Score for Seasonal Vaccine: 0.8518\n",
      "Mean ROC AUC Score: 0.8406\n",
      "Submission file 'submission.csv' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Drop 'respondent_id' since it's not a feature\n",
    "train_features.drop(columns=['respondent_id'], inplace=True)\n",
    "test_respondent_id = test_features['respondent_id']  # Save IDs for submission\n",
    "test_features.drop(columns=['respondent_id'], inplace=True)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = train_features.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = train_features.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Remove target variables from numerical features list\n",
    "numerical_features = [col for col in numerical_features if col not in ['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "\n",
    "# Ensure test dataset has all required columns\n",
    "missing_cols = set(train_features.columns) - set(test_features.columns)\n",
    "for col in missing_cols:\n",
    "    test_features[col] = np.nan  # Add missing columns as NaN\n",
    "\n",
    "# Reorder test features to match train features\n",
    "test_features = test_features[train_features.columns]\n",
    "\n",
    "# Define preprocessing steps\n",
    "numerical_imputer = SimpleImputer(strategy='median')  # Median for numerical features\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')  # Most frequent value for categorical features\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')  # One-hot encoding for categorical variables\n",
    "\n",
    "# Create transformers for numerical and categorical columns\n",
    "numerical_pipeline = Pipeline([(\"imputer\", numerical_imputer)])\n",
    "categorical_pipeline = Pipeline([(\"imputer\", categorical_imputer), (\"encoder\", one_hot_encoder)])\n",
    "\n",
    "# Combine pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_features),\n",
    "        (\"cat\", categorical_pipeline, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both train and test\n",
    "X_train_processed = preprocessor.fit_transform(train_features)\n",
    "X_test_processed = preprocessor.transform(test_features)\n",
    "\n",
    "# Convert processed data to DataFrame\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed)\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed)\n",
    "\n",
    "# Define target variables\n",
    "y_train = train_labels[['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_processed, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest classifiers for both target variables\n",
    "rf_h1n1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_seasonal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "rf_h1n1.fit(X_train, y_train['h1n1_vaccine'])\n",
    "rf_seasonal.fit(X_train, y_train['seasonal_vaccine'])\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "y_pred_h1n1 = rf_h1n1.predict_proba(X_val)[:, 1]\n",
    "y_pred_seasonal = rf_seasonal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute ROC AUC scores\n",
    "auc_h1n1 = roc_auc_score(y_val['h1n1_vaccine'], y_pred_h1n1)\n",
    "auc_seasonal = roc_auc_score(y_val['seasonal_vaccine'], y_pred_seasonal)\n",
    "mean_auc = (auc_h1n1 + auc_seasonal) / 2\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"ROC AUC Score for H1N1 Vaccine: {auc_h1n1:.4f}\")\n",
    "print(f\"ROC AUC Score for Seasonal Vaccine: {auc_seasonal:.4f}\")\n",
    "print(f\"Mean ROC AUC Score: {mean_auc:.4f}\")\n",
    "\n",
    "# Make final predictions on test data\n",
    "test_pred_h1n1 = rf_h1n1.predict_proba(X_test_processed)[:, 1]\n",
    "test_pred_seasonal = rf_seasonal.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Prepare submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"respondent_id\": test_respondent_id,\n",
    "    \"h1n1_vaccine\": test_pred_h1n1,\n",
    "    \"seasonal_vaccine\": test_pred_seasonal\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file 'submission.csv' has been created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
